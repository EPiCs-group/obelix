{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis of Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of data\n",
    "\n",
    "oh = pd.read_excel('descriptors_with_specific_buried_vol.xlsx').dropna()\n",
    "mace_averaged_oh = oh.groupby(['Cas']).mean()\n",
    "fig, ax = plt.subplots(5,3)\n",
    "descriptors = mace_averaged_oh.columns\n",
    "\n",
    "descriptor_count = 0\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        \n",
    "        ax[i, j].hist(x = mace_averaged_oh[descriptors[descriptor_count]], bins='auto', density=True)\n",
    "        ax[i, j].set_ylabel(descriptors[descriptor_count])\n",
    "        descriptor_count+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLR on selected data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def MLR(X, y):\n",
    "    # data = read_excel('PCA.xlsx')\n",
    "    # X = np.array([list(data['steric']),  list(data['elec']), list(data['geom'])]).T\n",
    "    # y = list(data['yield'])\n",
    "\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "\n",
    "    print('R2 = ', reg.score(X,y))\n",
    "\n",
    "    # print('coef: ', reg.coef_, 'intercept:', reg.intercept_)\n",
    "    return reg.score(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "import itertools\n",
    "\n",
    "data = mace_averaged_oh\n",
    "geom_keys = ['bite_angle']\n",
    "steric_keys = ['dipole', 'sasa','buried_volume']\n",
    "elec_keys = ['HOMO_LUMO_gap', 'dispersion', 'ea','nucleofugality', 'electrofugality', 'electrophilicity', 'nucleophilicity']\n",
    "\n",
    "pca1 = PCA(n_components=1)\n",
    "pca2 = PCA(n_components=1)\n",
    "pca3 = PCA(n_components=3)\n",
    "\n",
    "u_geom = pca1.fit_transform(data[geom_keys]) \n",
    "u_steric = pca2.fit_transform(data[steric_keys])\n",
    "u_elec = pca3.fit_transform(data[elec_keys])\n",
    "\n",
    "\n",
    "data['Cas'] = data.index\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "descriptor_order = 1\n",
    "\n",
    "dataframe['steric1'] = u_steric[:, 0]\n",
    "# dataframe['steric2'] = u_steric[:, 1]\n",
    "dataframe['elec1'] = u_elec[:, 0]\n",
    "dataframe['elec2'] = u_elec[:, 1]\n",
    "dataframe['elec3'] = u_elec[:, 2]\n",
    "dataframe['geom'] = u_geom[:, 0]\n",
    "\n",
    "### Add second order interactions\n",
    "for comb in itertools.combinations(['steric1', 'elec1','elec2','elec3', 'geom' ], 2):\n",
    "    dataframe[\"_\".join(comb)] = dataframe[comb[0]] * dataframe[comb[1]]\n",
    "\n",
    "# for index, key1 in enumerate(dataframe.keys()):\n",
    "#     for key2 in dataframe.keys()[index:]:\n",
    "#         dataframe[key1 + '_' + key2] = dataframe[key1]*dataframe[key2] \n",
    "\n",
    "dataframe['yield'] = data['yield'].to_list()\n",
    "dataframe['ee'] = data['ee'].to_list()\n",
    "\n",
    "dataframe['Cas'] = data['Cas'].to_list()\n",
    "dataframe['label_yield'] = pd.cut(x = dataframe['yield'], bins=[0, 0.8, 1],\n",
    "                     labels=[0, 1])\n",
    "\n",
    "dataframe.to_excel('PCA3_good_substrate_.xlsx')\n",
    "\n",
    "# X = np.array([list(dataframe['steric1']),list(dataframe['steric2']), list(dataframe['elec1']),  list(dataframe['elec2']), list(dataframe['elec3']), list(dataframe['geom'])])\n",
    "# print(X)\n",
    "# X2 = X**2\n",
    "# X3 = X**3\n",
    "\n",
    "X = dataframe.drop(['Cas', 'yield', 'label_yield', 'ee'], axis=1)\n",
    "# X = np.array([X, X2, X3])\n",
    "y = dataframe ['yield']\n",
    "# X = list(dataframe['elec1'])\n",
    "# y = list(dataframe['elec3'])\n",
    "\n",
    "MLR(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.scatter(mace_averaged_oh['buried_volume'], mace_averaged_oh['yield'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of `x` and `y`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array_like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "\n",
    "    Other parameters\n",
    "    ----------------\n",
    "    kwargs : `~matplotlib.patches.Patch` properties\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0),\n",
    "        width=ell_radius_x * 2,\n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor,\n",
    "        **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "\n",
    "arr = np.linspace(0, 50, 100).reshape((10, 10))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "cmap = plt.get_cmap('twilight')\n",
    "new_cmap = truncate_colormap(cmap, 0.2, 0.8)\n",
    "ax[0].imshow(arr, interpolation='nearest', cmap=cmap)\n",
    "ax[1].imshow(arr, interpolation='nearest', cmap=new_cmap)\n",
    "# plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_nstd = plt.subplots(figsize=(10, 8))\n",
    "plt.style.use('classic')\n",
    "plt.rcParams['image.cmap'] = new_cmap\n",
    "\n",
    "p1 = 'elec1'\n",
    "p2 = 'geom'\n",
    "heat_map = 'yield'\n",
    "### Change all ferrocenes\n",
    "x = dataframe[p1] \n",
    "y = dataframe[p2] \n",
    "\n",
    "mu = np.average(x), np.average(y)\n",
    "\n",
    "sc = ax_nstd.scatter(x, y, c=mace_averaged_oh[heat_map], s=210)\n",
    "fig.colorbar(sc)\n",
    "\n",
    "# 1365531-98-1\n",
    "\n",
    "# confidence_ellipse(x, y, ax_nstd, n_std=1,\n",
    "#     label=r'$1\\sigma$', edgecolor='firebrick')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=2,\n",
    "    label=r'95% confidence interval', edgecolor='fuchsia', linestyle='--')\n",
    "\n",
    "# confidence_ellipse(x, y, ax_nstd, n_std=3,\n",
    "#     label=r'$3\\sigma$', edgecolor='blue', linestyle=':')\n",
    "\n",
    "\n",
    "annot = ax_nstd.annotate(\"\", xy=(0,0), xytext=(20,20),textcoords=\"offset points\",\n",
    "                    bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                    arrowprops=dict(arrowstyle=\"->\"))\n",
    "annot.set_visible(False)\n",
    "names = list(dataframe['Cas'])\n",
    "\n",
    "def update_annot(ind):\n",
    "    pos = sc.get_offsets()[ind[\"ind\"][0]]\n",
    "    annot.xy = pos\n",
    "    text = \"{}, {}\".format(\" \".join(list(map(str,ind[\"ind\"]))), \n",
    "                           \" \".join([names[n] for n in ind[\"ind\"]]))\n",
    "    annot.set_text(text)\n",
    "    # annot.get_bbox_patch().set_facecolor(cmap(np.linalg.norm(c[ind[\"ind\"][0]])))\n",
    "    annot.get_bbox_patch().set_alpha(0.4)\n",
    "\n",
    "def hover(event):\n",
    "    vis = annot.get_visible()\n",
    "    try:\n",
    "        if event.inaxes == ax_nstd:\n",
    "            cont, ind = sc.contains(event)\n",
    "            if cont:\n",
    "                print(annot, end=\" \"*50 + '\\r')\n",
    "                update_annot(ind)\n",
    "                annot.set_visible(True)\n",
    "                fig.canvas.draw_idle()\n",
    "            else:\n",
    "                if vis:\n",
    "                    annot.set_visible(False)\n",
    "                    fig.canvas.draw_idle()\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "fig.canvas.mpl_connect(\"motion_notify_event\", hover)\n",
    "\n",
    "ax_nstd.scatter(mu[0], mu[1], s=10)\n",
    "ax_nstd.set_title('Different standard deviations')\n",
    "ax_nstd.set_xlabel(p1)\n",
    "ax_nstd.set_ylabel(p2)\n",
    "fig.set_facecolor('white')\n",
    "ax_nstd.legend()\n",
    "\n",
    "plt.savefig(\"std_{}_{}_heatmap_{}.png\".format(p1, p2, heat_map), dpi=400, bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_excel('PCA3_good_substrate_.xlsx')\n",
    "\n",
    "X = df.drop(['yield', 'Cas', 'label_yield', 'ee'], axis=1)\n",
    "\n",
    "y = df['label_yield']\n",
    "\n",
    "random_states = 30\n",
    "store = []\n",
    "for random_state in range(random_states):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "                                    random_state=random_state, \n",
    "                                    test_size=0.25, \n",
    "                                    shuffle=True)\n",
    "    lr = LogisticRegression(max_iter=1800)\n",
    "    lr.fit(X_train, y_train)\n",
    "    preds = lr.predict(X_test)\n",
    "    prob = preds==y_test\n",
    "\n",
    "    store.append(np.average(prob))\n",
    "\n",
    "print('size=', len(X_test))\n",
    "print('avg =', np.average(store), np.max(store), np.argmax(store))\n",
    "# print(np.average(prob))\n",
    "# a = pd.DataFrame(preds)\n",
    "# a.to_excel('preds.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = 10\n",
    "store = []\n",
    "for random_state in range(random_states):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "                                    random_state=random_state, \n",
    "                                    test_size=0.25, \n",
    "                                    shuffle=True)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    reg  = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print('R2 = ', reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "plt.style.use('classic')\n",
    "TOP_FEATURES = 7\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "                                random_state=42, \n",
    "                                test_size=0.25, \n",
    "                                shuffle=True)\n",
    "\n",
    "# model = LinearRegression()\n",
    "# reg  = model.fit(X_train, y_train)\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=700, max_depth=10, random_state=15)\n",
    "forest.fit(X_train,y_train)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std(\n",
    "    [tree.feature_importances_ for tree in forest.estimators_],\n",
    "    axis=0\n",
    ")\n",
    "indices = np.argsort(importances)[::-1]\n",
    "indices = indices[:TOP_FEATURES]\n",
    "\n",
    "print('Top features:')\n",
    "for f in range(TOP_FEATURES):\n",
    "    print('%d. feature %d (%f)' % (f + 1, indices[f], importances[indices[f]]))\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.title('Top feature importances')\n",
    "plt.bar(\n",
    "    range(TOP_FEATURES), \n",
    "    importances[indices],\n",
    "    yerr=std[indices], \n",
    ")\n",
    "plt.xticks(range(TOP_FEATURES), X_train.keys()._data[indices])\n",
    "fig.set_facecolor('white')\n",
    "plt.show()\n",
    "print(X_train.keys())\n",
    "plt.savefig('feature_ranking.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBClassifier\n",
    "import random\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                random_state=random.randrange(100), \n",
    "                                test_size=0.25, \n",
    "                                shuffle=True)\n",
    "\n",
    "\n",
    "m = StackingClassifier(\n",
    "    classifiers=[\n",
    "        LogisticRegression(max_iter=5000),\n",
    "        XGBClassifier(max_depth=10)\n",
    "    ],\n",
    "    use_probas=True,\n",
    "    meta_classifier=LogisticRegression()\n",
    ")\n",
    "\n",
    "m = m.fit(X_train,y_train)\n",
    "print(m.predict(X_test), y_test, 'R2', m.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                random_state=random.randrange(100), \n",
    "                                test_size=0.25, \n",
    "                                shuffle=True)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=random.randrange(100))\n",
    "regr = regr.fit(X_train, y_train)\n",
    "\n",
    "print(list(np.abs(np.array(y_test) - np.array(regr.predict(X_test)))/np.array(y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "oh = pd.read_excel('descriptors_OH.xlsx').dropna()\n",
    "dataframe =oh.groupby(['Cas']).mean()\n",
    "\n",
    "u_geom = pca.fit_transform(dataframe[geom_keys]) \n",
    "u_steric = pca.fit_transform(dataframe[steric_keys])\n",
    "u_elec = pca.fit_transform(dataframe[elec_keys])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Gen colors \n",
    "# reds = np.zeros((len(df['yield']), 3))\n",
    "# for i in range(len(df['yield'])):\n",
    "#     reds[i,:] = [df['yield'][i],  df['yield'][i]/10, df['yield'][i]/10]\n",
    "\n",
    "plt.rcParams['image.cmap'] = new_cmap\n",
    "print(max(np.abs(dataframe['ee'])))\n",
    "p = ax.scatter(u_geom, u_elec, u_steric, c=np.abs(dataframe['yield']), s=400)\n",
    "ax.set_xlabel('Geometric') # geom effects\n",
    "ax.set_ylabel('Electronic') \n",
    "ax.set_zlabel('Steric')\n",
    "fig.colorbar(p, fraction=0.025, pad=0.05)\n",
    "fig.set_facecolor('white')\n",
    "fig.savefig('3D_PCA.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ir-P bonds MLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pkg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import data from distances\n",
    "\n",
    "data = pd.read_excel('distances.xlsx')\n",
    "# print(data)\n",
    "data = data[data['yield'] > 0.32]\n",
    "X = data.drop(['yield'], axis=1)\n",
    "y = data['yield']\n",
    "\n",
    "# Skeleton bond ->> (2.34603586872537, 2.401789943590405)\n",
    "skeleton_bond = (2.34603586872537, 2.401789943590405)\n",
    "MLR(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from morfeus import read_xyz\n",
    "from numpy.linalg import norm\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def find_distance(xyz):\n",
    "    elements, coordinates = read_xyz(xyz)\n",
    "    P_coord = []\n",
    "    for ind_element, element in enumerate(elements):\n",
    "        if element == 'P':\n",
    "            P_coord.append(ind_element)\n",
    "        if element == 'Ir':\n",
    "            ind_Ir = ind_element\n",
    "\n",
    "    d1 = norm(coordinates[ind_Ir]  - coordinates[P_coord[0]])\n",
    "    d2 = norm(coordinates[ind_Ir]  - coordinates[P_coord[1]])\n",
    "\n",
    "    return d1, d2\n",
    "\n",
    "find_distance('xtbopt.xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "y =  mace_averaged_oh[heat_map]\n",
    "X = X[(X['elec1'] > -5) & (X['elec1'] < 4.6) & (X['steric1']<280)] \n",
    "p = plt.scatter(X['steric1'], X['elec1'], s=160)\n",
    "MLR(np.array(X['steric1']).reshape(-1,1), X['elec1'])\n",
    "\n",
    "print(y)\n",
    "# fig.colorbar()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigman dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find correlation between the yield column and all others.\n",
    "\n",
    "dataframe_sigman = pd.read_excel('JNJ_AH_Sigman_descriptors_CLEAN.xlsx').dropna()\n",
    "features = dataframe_sigman.drop(['JNJ Entry #', 'JNJ alias', 'CAS', 'Yield', 'Formula', 'Class','Sigman Ligand ID', 'Sigman ligand name'], axis = 1)\n",
    "y = dataframe_sigman['Yield']\n",
    "R2s = []\n",
    "for i in range(len(features)):\n",
    "    try:\n",
    "        plt.figure()\n",
    "        plt.scatter(features[features.columns[i]], y)\n",
    "        plt.savefig('presentation_images/{}.png'.format(features.columns[i]))\n",
    "        \n",
    "        R2 = MLR(np.array(features[features.columns[i]]).reshape(-1,1), y)\n",
    "        R2s.append(R2)\n",
    "        print(features.columns[i])\n",
    "        plt.close('all')\n",
    "    except Exception:   \n",
    "        plt.close('all')\n",
    "\n",
    "\n",
    "print(np.argmax(np.array(R2s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_excel('descriptors_SP.xlsx').dropna()\n",
    "sp = sp.groupby(['Cas']).mean()\n",
    "oh = mace_averaged_oh\n",
    "\n",
    "sp.columns = (i + '_bd' for i in sp.columns)\n",
    "common = sp.join(oh, how='inner')\n",
    "print(common)\n",
    "plt.figure()\n",
    "plt.scatter(common['cone_angle_bd'], common.cone_angle)\n",
    "plt.show()\n",
    "MLR(np.array(common['cone_angle_bd', 'bite_angle_bd']).reshape(-1, 1), common.cone_angle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BD OH correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%clear --output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79e2c953b88fc71b6c3c1dbda58af322da5a9c58bab14d6cfec9d635fb737f03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
