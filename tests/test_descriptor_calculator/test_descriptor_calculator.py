"""
This tests compares the descriptor values generated by OBeLiX for different
metal adducts and output types with the expected descriptor values for the
same set of files.

Data used in the test
----------------------
1. The expected descriptor values for the test cases must be provided in the
    expected_output folder. The expected descriptor values are provided in csv
    files with the naming convention descriptors_{metal_adduct}_{output_type}.csv.
    For example, the expected descriptor values for the "nbd" metal adduct with
    "xyz" output type must be provided in a file named
    descriptors_nbd_xyz.csv in the expected_output folder.

2. The input files for the test cases must be provided in the data folder. The
    input files are organized in the following folder structure:
    data
    ├── nbd
    │   ├── crest
    │   ├── gaussian
    │   └── xyz
    └── pristine
        ├── crest
        ├── gaussian
        └── xyz

    The input files for the "nbd" metal adduct are provided in the nbd folder,
    and the input files for the "pristine" metal adduct are provided in the
    pristine folder. The input files for each metal adduct are further organized
    based on the output type (crest, gaussian, or xyz).

3. The output folder is used to store the output csv files generated by the
    test cases. The output folder is created in the same directory as the test
    file.


Test steps
----------

1. Calculate the descriptors for the input files in the data folder for the
    given set of metal adducts and output types.
2. Save the descriptor values in a csv file in the output folder.
3. Compare the descriptor values in the output csv file with the expected
    descriptor values for the same set of files using the test cases.


Test cases
----------

1. test_descriptor_values: Compares the descriptor values in the output csv
file with the expected descriptor values for the same set of files.
2. test_index_values: Compares the index values in the output csv file with
the expected index values for the same set of files.
3. test_element_values: Compares the element values in the output csv file
with the expected element values for the same set of files.
4. test_filename_values: Compares the filename values in the output csv file
with the expected filename values for the same set of files.


Parameterization
----------------
Parametrization allows the same test cases to be run with different sets of
parameters. In this test, the test cases are parametrized with the metal adduct
and output type. The test cases are run with the following sets of parameters:
1. ("nbd", "xyz")
2. ("pristine", "xyz")
3. ("nbd", "gaussian")
4. ("pristine", "crest")


Fixtures
--------

A fixture is a function that is run before each test case. In this test, the
calculate_descriptors fixture is used to calculate the descriptors for the input files in the data folder for the given set of metal adducts and output types.


When this test is run, the following sequence of events occur:
--------------------------------------------------------------

1. The calculate_descriptors fixture is called with the first set of parameters ("nbd", "xyz").
2. The descriptors are calculated for the files in the "nbd" folder with output type "xyz".
3. The output csv file with the descriptor values is saved in the output folder.
4. The test_descriptor_values, test_index_values, test_element_values, and test_filename_values test cases are run with the output csv file generated in step 3.
5. The output folder generated in step 3 is deleted.
6. The same steps are repeated for the other sets of parameters: ("pristine", "xyz"), ("nbd", "gaussian"), and ("pristine", "crest").


Running the test
----------------

Run this test only:
Execute `pytest -v tests/test_descriptor_calculator/test_descriptor_calculator.py` in the terminal from the root directory of the repository.

Run all the tests in the repository:
`pytest -v` in the terminal from the root directory of the repository.

"""

import os
import shutil

import numpy as np
import pandas as pd
import pytest

from obelix.descriptor_calculator import Descriptors


@pytest.fixture(scope="class")
def calculate_descriptors(request):
    metal_adduct, output_type = request.param
    path_to_input = os.path.join(
        os.path.abspath(os.path.dirname(__file__)),
        "data",
        metal_adduct,
        output_type,
    )
    descriptors = Descriptors(
        central_atom="Rh",
        path_to_workflow=path_to_input,
        output_type=output_type,
    )

    if output_type in ["xyz", "crest"]:
        descriptors.calculate_morfeus_descriptors(
            geom_type="BD", solvent=None, printout=False, metal_adduct=metal_adduct
        )
    elif output_type == "gaussian":
        descriptors.calculate_dft_descriptors_from_log(
            geom_type="BD",
            solvent=None,
            extract_xyz_from_log=True,
            printout=False,
            metal_adduct=metal_adduct,
            plot_steric_map=False,
        )
    else:
        raise ValueError("The output_type must be one of 'xyz', 'crest' or 'gaussian'.")

    output_dir = os.path.join(os.path.abspath(os.path.dirname(__file__)), "output")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    output_file_path = os.path.join(output_dir, "descriptors.csv")
    descriptors.descriptor_df.to_csv(output_file_path, index=False)

    yield metal_adduct, output_type

    shutil.rmtree(output_dir)


@pytest.mark.parametrize(
    "calculate_descriptors",
    [
        ("nbd", "xyz"),
        ("pristine", "xyz"),
        ("nbd", "gaussian"),
        ("pristine", "crest"),
    ],
    indirect=True,
    ids=[
        "nbd-xyz",
        "pristine-xyz",
        "nbd-gaussian",
        "pristine-crest",
    ],  # these ids prints the metal_adduct and output_type in the test name
    # in the pytest report, making it easier to see the pass/fail status of
    # each test case for each combination of metal_adduct and output_type
)
class TestDescriptorCalculation:
    def test_descriptor_values(self, calculate_descriptors):
        metal_adduct, output_type = calculate_descriptors
        self.compare_csv_contents(
            metal_adduct,
            output_type,
            exclude_columns=["index", "element", "filename_tud"],
        )

    def test_index_values(self, calculate_descriptors):
        metal_adduct, output_type = calculate_descriptors
        self.compare_csv_contents(metal_adduct, output_type, include_columns=["index"])

    def test_element_values(self, calculate_descriptors):
        metal_adduct, output_type = calculate_descriptors
        self.compare_csv_contents(
            metal_adduct, output_type, include_columns=["element"]
        )

    def test_filename_values(self, calculate_descriptors):
        metal_adduct, output_type = calculate_descriptors
        self.compare_csv_contents(
            metal_adduct, output_type, include_columns=["filename_tud"]
        )

    def compare_csv_contents(
        self,
        metal_adduct,
        output_type,
        include_columns=None,
        exclude_columns=None,
    ):
        """
        This is a helper function to compare the contents of the output csv
        file with the expected csv file. Extracting out this function helps to
        avoid code duplication in the test methods.
        """
        path_expected_csv = os.path.join(
            os.path.abspath(os.path.dirname(__file__)),
            "expected_output",
            f"descriptors_{metal_adduct}_{output_type}.csv",
        )
        output_csv = os.path.join(
            os.path.abspath(os.path.dirname(__file__)),
            "output",
            "descriptors.csv",
        )

        expected_df = pd.read_csv(path_expected_csv)
        output_df = pd.read_csv(output_csv)

        # Filter the columns based on the include_columns or exclude_columns
        # parameter and compare the values. If include_columns is provided,
        # use DataFrame.equals for comparison. If exclude_columns is provided
        # use np.allclose for comparison. This is because DataFrame.equals is
        # used for non-numeric data comparison (index, filenme and element
        # values), while np.allclose is used for numeric data comparison (descriptor values).
        if include_columns:
            filtered_columns = expected_df.columns[
                expected_df.columns.str.contains("|".join(include_columns))
            ]
            expected_df = expected_df.loc[:, filtered_columns]
            output_df = output_df.loc[:, filtered_columns]
            # Use DataFrame.equals for non-numeric data comparison
            assert expected_df.equals(output_df), (
                f"The {include_columns} values in the output csv file do not"
                f"match the expected values for {metal_adduct} with {output_type}."
            )
        elif exclude_columns:
            # For numeric data, use np.allclose after excluding non-numeric columns
            filtered_columns = expected_df.columns[
                ~expected_df.columns.str.contains("|".join(exclude_columns))
            ]
            expected_df = expected_df.loc[:, filtered_columns]
            output_df = output_df.loc[:, filtered_columns]

            output_descriptor_values = output_df.to_numpy()

            # Convert True/False values to 1/0
            output_descriptor_values = np.where(
                output_descriptor_values is True, 1, output_descriptor_values
            )
            output_descriptor_values = np.where(
                output_descriptor_values is False, 0, output_descriptor_values
            )

            # Convert each element in the array to a numeric type (float by
            # default). If an element cannot be converted (e.g., a string that
            # doesn't represent a number), it is replaced with NaN (Not a
            # Number), as a result of the errors='coerce' parameter. This step
            # ensures that the entire array is numeric, which is a
            # prerequisite for using np.allclose.
            output_descriptor_values = pd.to_numeric(
                output_descriptor_values.flatten(), errors="coerce"
            ).reshape(output_descriptor_values.shape)

            expected_descriptor_values = expected_df.to_numpy()

            expected_descriptor_values = np.where(
                expected_descriptor_values is True, 1, expected_descriptor_values
            )
            expected_descriptor_values = np.where(
                expected_descriptor_values is False, 0, expected_descriptor_values
            )

            expected_descriptor_values = pd.to_numeric(
                expected_descriptor_values.flatten(), errors="coerce"
            ).reshape(expected_descriptor_values.shape)

            assert np.allclose(
                output_descriptor_values, expected_descriptor_values, equal_nan=True
            ), (
                f"The descriptor values in the output csv file do not match"
                f"the expected descriptor values for {metal_adduct} with {output_type}."
            )
        else:
            raise ValueError(
                "Either include_columns or exclude_columns must be provided."
            )
